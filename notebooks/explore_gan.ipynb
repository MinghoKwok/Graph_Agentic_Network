{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Exploring Graph Agentic Network\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates how to use the Graph Agentic Network framework for node classification tasks.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import networkx as nx\\n\",\n",
    "    \"from tqdm.notebook import tqdm\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add parent directory to path\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import GAN modules\\n\",\n",
    "    \"import config\\n\",\n",
    "    \"from gan.llm import MockLLMInterface\\n\",\n",
    "    \"from gan.graph import GraphAgenticNetwork\\n\",\n",
    "    \"from data.dataset import load_or_create_dataset\\n\",\n",
    "    \"from gan.utils import seed_everything, visualize_graph, evaluate_node_classification\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Check GPU Availability\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check if CUDA is available\\n\",\n",
    "    \"if torch.cuda.is_available():\\n\",\n",
    "    \"    print(f\\\"CUDA is available with {torch.cuda.device_count()} device(s)\\\")\\n\",\n",
    "    \"    for i in range(torch.cuda.device_count()):\\n\",\n",
    "    \"        print(f\\\"  Device {i}: {torch.cuda.get_device_name(i)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Set default device\\n\",\n",
    "    \"    device = torch.device(\\\"cuda:0\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"CUDA is not available, using CPU\\\")\\n\",\n",
    "    \"    device = torch.device(\\\"cpu\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Load a Dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"For quick experimentation, we'll use a small subgraph of the OGB-Arxiv dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Set random seed for reproducibility\\n\",\n",
    "    \"seed_everything(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load dataset\\n\",\n",
    "    \"use_subgraph = True  # Use a smaller graph for faster processing\\n\",\n",
    "    \"subgraph_size = 500  # Number of nodes in the subgraph\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataset = load_or_create_dataset(\\n\",\n",
    "    \"    'ogbn-arxiv',\\n\",\n",
    "    \"    use_subgraph=use_subgraph,\\n\",\n",
    "    \"    subgraph_size=subgraph_size\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract dataset components\\n\",\n",
    "    \"adj_matrix = dataset['adj_matrix']\\n\",\n",
    "    \"node_features = dataset['node_features']\\n\",\n",
    "    \"labels = dataset['labels']\\n\",\n",
    "    \"train_idx = dataset['train_idx']\\n\",\n",
    "    \"val_idx = dataset['val_idx']\\n\",\n",
    "    \"test_idx = dataset['test_idx']\\n\",\n",
    "    \"num_classes = dataset['num_classes']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loaded {'subgraph of ' if use_subgraph else ''}OGB-Arxiv dataset\\\")\\n\",\n",
    "    \"print(f\\\"  Nodes: {adj_matrix.shape[0]}\\\")\\n\",\n",
    "    \"print(f\\\"  Edges: {adj_matrix.sum().item() / 2:.0f}\\\")\\n\",\n",
    "    \"print(f\\\"  Features: {node_features.shape[1]}\\\")\\n\",\n",
    "    \"print(f\\\"  Classes: {num_classes}\\\")\\n\",\n",
    "    \"print(f\\\"  Train/Val/Test split: {len(train_idx)}/{len(val_idx)}/{len(test_idx)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Visualize the Graph\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's visualize a portion of the graph to understand its structure.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# For large graphs, visualize only a small section\\n\",\n",
    "    \"max_nodes_to_plot = 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"if adj_matrix.shape[0] > max_nodes_to_plot:\\n\",\n",
    "    \"    # Plot a smaller section\\n\",\n",
    "    \"    subset_nodes = torch.randperm(adj_matrix.shape[0])[:max_nodes_to_plot]\\n\",\n",
    "    \"    sub_adj = adj_matrix[subset_nodes][:, subset_nodes]\\n\",\n",
    "    \"    sub_labels = labels[subset_nodes]\\n\",\n",
    "    \"    title = f\\\"Subset of {max_nodes_to_plot} nodes\\\"\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # Plot the whole graph\\n\",\n",
    "    \"    sub_adj = adj_matrix\\n\",\n",
    "    \"    sub_labels = labels\\n\",\n",
    "    \"    title = \\\"Full graph\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize with colors based on labels\\n\",\n",
    "    \"visualize_graph(\\n\",\n",
    "    \"    sub_adj, \\n\",\n",
    "    \"    node_colors=sub_labels.numpy(), \\n\",\n",
    "    \"    title=title\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Create a Graph Agentic Network\\n\",\n",
    "    \"\\n\",\n",
    "    \"For the purpose of this demo, we'll use a mock LLM interface to avoid requiring an actual LLM connection.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize mock LLM interface\\n\",\n",
    "    \"llm_interface = MockLLMInterface()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create GAN model\\n\",\n",
    "    \"num_layers = 2\\n\",\n",
    "    \"gan = GraphAgenticNetwork(\\n\",\n",
    "    \"    adj_matrix=adj_matrix,\\n\",\n",
    "    \"    node_features=node_features,\\n\",\n",
    "    \"    llm_interface=llm_interface,\\n\",\n",
    "    \"    labels=labels,\\n\",\n",
    "    \"    num_layers=num_layers\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Created Graph Agentic Network with {num_layers} layers\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Run the Graph Agentic Network\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's run the GAN on our dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Run GAN\\n\",\n",
    "    \"batch_size = 50  # Process nodes in batches for larger graphs\\n\",\n",
    "    \"print(f\\\"Running Graph Agentic Network...\\\")\\n\",\n",
    "    \"gan.forward(batch_size=batch_size)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Evaluate Results\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's evaluate the performance of our GAN model.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get predictions\\n\",\n",
    "    \"predictions = gan.get_node_predictions()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate results\\n\",\n",
    "    \"train_metrics = evaluate_node_classification(predictions[train_idx], labels[train_idx])\\n\",\n",
    "    \"val_metrics = evaluate_node_classification(predictions[val_idx], labels[val_idx])\\n\",\n",
    "    \"test_metrics = evaluate_node_classification(predictions[test_idx], labels[test_idx])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"GAN Results:\\\")\\n\",\n",
    "    \"print(f\\\"  Train Accuracy: {train_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Val Accuracy: {val_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Test Accuracy: {test_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Test F1 (Micro): {test_metrics['f1_micro']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Test F1 (Macro): {test_metrics['f1_macro']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Analyze Node Actions\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze what actions the nodes took during the GAN processing.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get node memory (action history)\\n\",\n",
    "    \"node_memory = gan.get_node_memory()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Count actions by type\\n\",\n",
    "    \"action_counts = {}\\n\",\n",
    "    \"for node_id, memory in node_memory.items():\\n\",\n",
    "    \"    for entry in memory:\\n\",\n",
    "    \"        action = entry['result']['action']\\n\",\n",
    "    \"        if action not in action_counts:\\n\",\n",
    "    \"            action_counts[action] = 0\\n\",\n",
    "    \"        action_counts[action] += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot action distribution\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"plt.bar(action_counts.keys(), action_counts.values())\\n\",\n",
    "    \"plt.title('Action Type Distribution')\\n\",\n",
    "    \"plt.xlabel('Action Type')\\n\",\n",
    "    \"plt.ylabel('Count')\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, (action, count) in enumerate(action_counts.items()):\\n\",\n",
    "    \"    plt.text(i, count + 0.5, str(count), ha='center')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Examine Individual Node Behavior\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's examine the behavior of individual nodes in more detail.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Select a random node to examine\\n\",\n",
    "    \"node_id = np.random.randint(0, adj_matrix.shape[0])\\n\",\n",
    "    \"node_history = node_memory.get(node_id, [])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Examining behavior of Node {node_id}\\\")\\n\",\n",
    "    \"print(f\\\"True label: {labels[node_id].item()}\\\")\\n\",\n",
    "    \"print(f\\\"Predicted label: {predictions[node_id].item() if node_id < len(predictions) else 'N/A'}\\\")\\n\",\n",
    "    \"print(f\\\"Number of actions: {len(node_history)}\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, entry in enumerate(node_history):\\n\",\n",
    "    \"    print(f\\\"Action {i+1} (Layer {entry['layer']})\\\")\\n\",\n",
    "    \"    print(f\\\"  Type: {entry['result']['action']}\\\")\\n\",\n",
    "    \"    print(f\\\"  Details: {entry['result']}\\\\n\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"To extend this exploration, you could:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Replace the MockLLMInterface with a real LLM connection\\n\",\n",
    "    \"2. Try different datasets or larger subgraphs\\n\",\n",
    "    \"3. Experiment with different numbers of layers and batch sizes\\n\",\n",
    "    \"4. Implement custom node agent behaviors\\n\",\n",
    "    \"5. Compare with traditional GNN baselines\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 自动添加项目根路径\n",
    "sys.path.append(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OGB-Arxiv dataset from /common/home/mg1998/Graph/GAN/Graph_Agentic_Network/data/ogbn-arxiv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/mg1998/miniforge3/envs/gan/lib/python3.10/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from data.dataset import load_or_create_dataset\n",
    "dataset = load_or_create_dataset(\"ogbn-arxiv\", use_subgraph=True, subgraph_size=100)\n",
    "\n",
    "for key, value in dataset.items():\n",
    "    print(f\"{key}: {type(value)}, shape: {getattr(value, 'shape', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
