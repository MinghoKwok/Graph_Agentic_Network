{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Exploring Graph Agentic Network\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates how to use the Graph Agentic Network framework for node classification tasks.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import networkx as nx\\n\",\n",
    "    \"from tqdm.notebook import tqdm\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add parent directory to path\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import GAN modules\\n\",\n",
    "    \"import config\\n\",\n",
    "    \"from gan.llm import MockLLMInterface\\n\",\n",
    "    \"from gan.graph import GraphAgenticNetwork\\n\",\n",
    "    \"from data.dataset import load_or_create_dataset\\n\",\n",
    "    \"from gan.utils import seed_everything, visualize_graph, evaluate_node_classification\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Check GPU Availability\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check if CUDA is available\\n\",\n",
    "    \"if torch.cuda.is_available():\\n\",\n",
    "    \"    print(f\\\"CUDA is available with {torch.cuda.device_count()} device(s)\\\")\\n\",\n",
    "    \"    for i in range(torch.cuda.device_count()):\\n\",\n",
    "    \"        print(f\\\"  Device {i}: {torch.cuda.get_device_name(i)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Set default device\\n\",\n",
    "    \"    device = torch.device(\\\"cuda:0\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"CUDA is not available, using CPU\\\")\\n\",\n",
    "    \"    device = torch.device(\\\"cpu\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Load a Dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"For quick experimentation, we'll use a small subgraph of the OGB-Arxiv dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Set random seed for reproducibility\\n\",\n",
    "    \"seed_everything(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load dataset\\n\",\n",
    "    \"use_subgraph = True  # Use a smaller graph for faster processing\\n\",\n",
    "    \"subgraph_size = 500  # Number of nodes in the subgraph\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataset = load_or_create_dataset(\\n\",\n",
    "    \"    'ogbn-arxiv',\\n\",\n",
    "    \"    use_subgraph=use_subgraph,\\n\",\n",
    "    \"    subgraph_size=subgraph_size\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract dataset components\\n\",\n",
    "    \"adj_matrix = dataset['adj_matrix']\\n\",\n",
    "    \"node_features = dataset['node_features']\\n\",\n",
    "    \"labels = dataset['labels']\\n\",\n",
    "    \"train_idx = dataset['train_idx']\\n\",\n",
    "    \"val_idx = dataset['val_idx']\\n\",\n",
    "    \"test_idx = dataset['test_idx']\\n\",\n",
    "    \"num_classes = dataset['num_classes']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loaded {'subgraph of ' if use_subgraph else ''}OGB-Arxiv dataset\\\")\\n\",\n",
    "    \"print(f\\\"  Nodes: {adj_matrix.shape[0]}\\\")\\n\",\n",
    "    \"print(f\\\"  Edges: {adj_matrix.sum().item() / 2:.0f}\\\")\\n\",\n",
    "    \"print(f\\\"  Features: {node_features.shape[1]}\\\")\\n\",\n",
    "    \"print(f\\\"  Classes: {num_classes}\\\")\\n\",\n",
    "    \"print(f\\\"  Train/Val/Test split: {len(train_idx)}/{len(val_idx)}/{len(test_idx)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Visualize the Graph\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's visualize a portion of the graph to understand its structure.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# For large graphs, visualize only a small section\\n\",\n",
    "    \"max_nodes_to_plot = 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"if adj_matrix.shape[0] > max_nodes_to_plot:\\n\",\n",
    "    \"    # Plot a smaller section\\n\",\n",
    "    \"    subset_nodes = torch.randperm(adj_matrix.shape[0])[:max_nodes_to_plot]\\n\",\n",
    "    \"    sub_adj = adj_matrix[subset_nodes][:, subset_nodes]\\n\",\n",
    "    \"    sub_labels = labels[subset_nodes]\\n\",\n",
    "    \"    title = f\\\"Subset of {max_nodes_to_plot} nodes\\\"\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # Plot the whole graph\\n\",\n",
    "    \"    sub_adj = adj_matrix\\n\",\n",
    "    \"    sub_labels = labels\\n\",\n",
    "    \"    title = \\\"Full graph\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize with colors based on labels\\n\",\n",
    "    \"visualize_graph(\\n\",\n",
    "    \"    sub_adj, \\n\",\n",
    "    \"    node_colors=sub_labels.numpy(), \\n\",\n",
    "    \"    title=title\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Create a Graph Agentic Network\\n\",\n",
    "    \"\\n\",\n",
    "    \"For the purpose of this demo, we'll use a mock LLM interface to avoid requiring an actual LLM connection.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize mock LLM interface\\n\",\n",
    "    \"llm_interface = MockLLMInterface()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create GAN model\\n\",\n",
    "    \"num_layers = 2\\n\",\n",
    "    \"gan = GraphAgenticNetwork(\\n\",\n",
    "    \"    adj_matrix=adj_matrix,\\n\",\n",
    "    \"    node_features=node_features,\\n\",\n",
    "    \"    llm_interface=llm_interface,\\n\",\n",
    "    \"    labels=labels,\\n\",\n",
    "    \"    num_layers=num_layers\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Created Graph Agentic Network with {num_layers} layers\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Run the Graph Agentic Network\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's run the GAN on our dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Run GAN\\n\",\n",
    "    \"batch_size = 50  # Process nodes in batches for larger graphs\\n\",\n",
    "    \"print(f\\\"Running Graph Agentic Network...\\\")\\n\",\n",
    "    \"gan.forward(batch_size=batch_size)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Evaluate Results\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's evaluate the performance of our GAN model.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get predictions\\n\",\n",
    "    \"predictions = gan.get_node_predictions()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate results\\n\",\n",
    "    \"train_metrics = evaluate_node_classification(predictions[train_idx], labels[train_idx])\\n\",\n",
    "    \"val_metrics = evaluate_node_classification(predictions[val_idx], labels[val_idx])\\n\",\n",
    "    \"test_metrics = evaluate_node_classification(predictions[test_idx], labels[test_idx])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"GAN Results:\\\")\\n\",\n",
    "    \"print(f\\\"  Train Accuracy: {train_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Val Accuracy: {val_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Test Accuracy: {test_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Test F1 (Micro): {test_metrics['f1_micro']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Test F1 (Macro): {test_metrics['f1_macro']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Analyze Node Actions\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze what actions the nodes took during the GAN processing.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get node memory (action history)\\n\",\n",
    "    \"node_memory = gan.get_node_memory()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Count actions by type\\n\",\n",
    "    \"action_counts = {}\\n\",\n",
    "    \"for node_id, memory in node_memory.items():\\n\",\n",
    "    \"    for entry in memory:\\n\",\n",
    "    \"        action = entry['result']['action']\\n\",\n",
    "    \"        if action not in action_counts:\\n\",\n",
    "    \"            action_counts[action] = 0\\n\",\n",
    "    \"        action_counts[action] += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot action distribution\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"plt.bar(action_counts.keys(), action_counts.values())\\n\",\n",
    "    \"plt.title('Action Type Distribution')\\n\",\n",
    "    \"plt.xlabel('Action Type')\\n\",\n",
    "    \"plt.ylabel('Count')\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, (action, count) in enumerate(action_counts.items()):\\n\",\n",
    "    \"    plt.text(i, count + 0.5, str(count), ha='center')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Examine Individual Node Behavior\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's examine the behavior of individual nodes in more detail.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Select a random node to examine\\n\",\n",
    "    \"node_id = np.random.randint(0, adj_matrix.shape[0])\\n\",\n",
    "    \"node_history = node_memory.get(node_id, [])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Examining behavior of Node {node_id}\\\")\\n\",\n",
    "    \"print(f\\\"True label: {labels[node_id].item()}\\\")\\n\",\n",
    "    \"print(f\\\"Predicted label: {predictions[node_id].item() if node_id < len(predictions) else 'N/A'}\\\")\\n\",\n",
    "    \"print(f\\\"Number of actions: {len(node_history)}\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, entry in enumerate(node_history):\\n\",\n",
    "    \"    print(f\\\"Action {i+1} (Layer {entry['layer']})\\\")\\n\",\n",
    "    \"    print(f\\\"  Type: {entry['result']['action']}\\\")\\n\",\n",
    "    \"    print(f\\\"  Details: {entry['result']}\\\\n\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"To extend this exploration, you could:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Replace the MockLLMInterface with a real LLM connection\\n\",\n",
    "    \"2. Try different datasets or larger subgraphs\\n\",\n",
    "    \"3. Experiment with different numbers of layers and batch sizes\\n\",\n",
    "    \"4. Implement custom node agent behaviors\\n\",\n",
    "    \"5. Compare with traditional GNN baselines\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
