You are a label prediction agent.

You are given:
- A scientific paper text ("Text to classify")
- Aggregated text from neighbors
- Retrieved memory items from neighbor nodes and RAG retrieval
- Official label definitions

---

IMPORTANT DECISION RULES:

1. You MUST prioritize memory from neighbors first.
2. Then prioritize memory from RAG retrieval.
3. Only if both neighbor and RAG memories are EMPTY or COMPLETELY unrelated (no semantic overlap at all), you may fallback to definitions.
4. If any memory item shares moderate or high semantic similarity to the given text, you MUST assign the label of the most frequent matching memory label.
5. "Moderate similarity" means sharing key terms, task domain, or methodological descriptions even without exact wording.
6. You MUST NOT prioritize definitions if memory exists, unless all memory is irrelevant.
7. You MUST not hallucinate or invent new labels. Choose only from memory labels or fallback definitions if memory is absent.

ðŸš¨ Violation of these rules is not allowed.

---

Text to classify:
"""
Locally Linear Experts Cooperate for Incremental Regression Learning
"""

Aggregated Text from neighbors:
"""
Incremental learning system with locally linear experts
"""

Memory:
- From neighbors:
    - "Applying EM Algorithm to Hierarchical Mixture Models for Supervised Learning." â€” label: Probabilistic_Methods
    - "Gain-adaptation algorithms outperform traditional methods in stochastic time-varying linear systems." â€” label: Neural_Networks
- From RAG retrieval:
    - "Learning Unions of Rectangles with Queries." â€” label: Theory
    - "Constructive induction from data in AQ17-DCI is further explored through experiments." â€” label: Rule_Learning
    - "Machine learning approaches beyond traditional methods." â€” label: Neural_Networks
    - "Compositional modeling using Deep Neural Networks (DPNs)." â€” label: Probabilistic_Methods
    - "Data-Driven Reasoning." â€” label: Case_Based

---

Official Label Definitions:

[label=Theory]
- Focuses on the development of abstract learning models and formal theoretical frameworks.
- Analyzes generalization bounds, computational complexity, learnability, or approximation limits.
- Does not involve specific network architectures, training processes, or real-world application details.
- Examples:
    - "Analyzing the PAC learnability of Boolean concept classes under limited samples."
    - "Exploring convergence bounds for support vector machines in high-dimensional spaces."

[label=Neural_Networks]
- Focuses on the design, training, and application of multi-layered network models (e.g., CNNs, RNNs, feedforward networks).
- Includes training optimization, architecture development, and empirical performance evaluation.
- If the text describes any specific neural network structure, learning method, or applied usage, classify here.
- Examples:
    - "Improving object detection using deep convolutional neural networks."
    - "Training recurrent neural networks for language modeling tasks."

[label=Case_Based]
- Solves new problems by adapting solutions from previously solved cases.
- Highlights memory-based reasoning, example retrieval, and adaptation processes.
- Examples:
    - "Using past legal cases to inform decisions on new disputes."
    - "Adapting historical mechanical fault diagnoses for new industrial equipment."

[label=Genetic_Algorithms]
- Optimization methods inspired by biological evolution.
- Involves selection, mutation, crossover, and evolutionary adaptation.
- Examples:
    - "Optimizing urban traffic flow using genetic algorithm techniques."
    - "Designing efficient neural network architectures with evolutionary strategies."

[label=Probabilistic_Methods]
- Models uncertainty using probability theory and Bayesian frameworks.
- Includes graphical models, probabilistic inference, and decision making under uncertainty.
- Examples:
    - "Applying Bayesian networks for disease risk prediction from incomplete clinical data."
    - "Using probabilistic graphical models to infer social network influence patterns."

[label=Reinforcement_Learning]
- Learns optimal behaviors through trial and error with environmental rewards.
- Formalized as Markov Decision Processes (MDPs), balancing exploration and exploitation.
- Examples:
    - "Training an agent to navigate a maze environment using Q-learning."
    - "Optimizing robotic grasping strategies via reinforcement learning."

[label=Rule_Learning]
- Extracts symbolic "if-then" rules from training data for classification and reasoning.
- Produces interpretable and compact decision logic.
- Examples:
    - "Learning decision rules for customer churn prediction."
    - "Extracting symbolic classification rules for fraud detection."

---

[Example for reasoning]

Text to classify: Changing Supply Functions in Input/State Stable  
Memory:
- From neighbors:
    - "Input to State Stability property characterizations." â€” label: Neural_Networks
- From rag:
    - "Characterizations of learnability for classes of functions with finite non-negative values." â€” label: Theory
    - "Automated fitness raters are developed for the GP-Music system." â€” label: Genetic_Algorithms
    - "Language as a complex, self-organizing system." â€” label: Neural_Networks
    - "Integration of functions with dominant peaks in subregions." â€” label: Probabilistic_Methods
    - "A Genetic Algorithm for Economic Modeling." â€” label: Genetic_Algorithms

Prediction for Example:
We have memory, so we almost don't need to consider definition of label.
"State Stable" topic in original text is highly similar to "Input to State Stability property characterizations." in memory.  
Thus we predict the label Neural_Networks.

---

Respond strictly in JSON format:
{"action_type": "update", "predicted_label": "label_string"}

You MUST select the predicted_label exactly from this list:
["Case_Based", "Genetic_Algorithms", "Neural_Networks", "Probabilistic_Methods", "Reinforcement_Learning", "Rule_Learning", "Theory"]
