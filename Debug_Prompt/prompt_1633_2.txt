You are a label prediction agent.

You are given:
- A scientific paper text ("Text to classify")
- Aggregated text from neighbors
- Retrieved memory items from neighbor nodes and RAG retrieval
- Official label definitions

---

IMPORTANT DECISION RULES:

1. You MUST prioritize memory from neighbors first.
2. Then prioritize memory from RAG retrieval.
3. Only if both neighbor and RAG memories are EMPTY or COMPLETELY unrelated (no semantic overlap at all), you may fallback to definitions.
4. If any memory item shares moderate or high semantic similarity to the given text, you MUST assign the label of the most frequent matching memory label.
5. "Moderate similarity" means sharing key terms, task domain, or methodological descriptions even without exact wording.
6. You MUST NOT prioritize definitions if memory exists, unless all memory is irrelevant.
7. You MUST not hallucinate or invent new labels. Choose only from memory labels or fallback definitions if memory is absent.

ðŸš¨ Violation of these rules is not allowed.

---

Text to classify:
"""
Title: Changing Supply Functions in Input/State Stable Systems
Abstract: We consider the problem of characterizing possible supply functions for a given dissipative nonlinear system, and provide a result that allows some freedom in the modification of such functions.
"""

Aggregated Text from neighbors:
"""
Supply functions in stable systems with modifications.
"""

Memory:
- From neighbors:
    - "Input to State Stability property characterizations." â€” label: label_2
- From RAG retrieval:
    - "Characterizations of learnability for classes of functions with finite non-negative values." â€” label: label_6
    - "Automated fitness raters are developed for the GP-Music system to evaluate and improve musical compositions generated by genetic programming." â€” label: label_1
    - "Language as a complex, self-organizing system." â€” label: label_2
    - "Integration of functions with dominant peaks in subregions." â€” label: label_3
    - "A Genetic Algorithm for Economic Modeling." â€” label: label_1

---

Official Label Definitions:

[label=label_6]
- Focuses on the development of abstract learning models and formal theoretical frameworks.
- Analyzes generalization bounds, computational complexity, learnability, or approximation limits.
- Does not involve specific network architectures, training processes, or real-world application details.
- Examples:
    - "Analyzing the PAC learnability of Boolean concept classes under limited samples."
    - "Exploring convergence bounds for support vector machines in high-dimensional spaces."

[label=label_2]
- Focuses on the design, training, and application of multi-layered network models (e.g., CNNs, RNNs, feedforward networks).
- Includes training optimization, architecture development, and empirical performance evaluation.
- If the text describes any specific neural network structure, learning method, or applied usage, classify here.
- Examples:
    - "Improving object detection using deep convolutional neural networks."
    - "Training recurrent neural networks for language modeling tasks."

[label=label_0]
- Solves new problems by adapting solutions from previously solved cases.
- Highlights memory-based reasoning, example retrieval, and adaptation processes.
- Examples:
    - "Using past legal cases to inform decisions on new disputes."
    - "Adapting historical mechanical fault diagnoses for new industrial equipment."

[label=label_1]
- Optimization methods inspired by biological evolution.
- Involves selection, mutation, crossover, and evolutionary adaptation.
- Examples:
    - "Optimizing urban traffic flow using genetic algorithm techniques."
    - "Designing efficient neural network architectures with evolutionary strategies."

[label=label_3]
- Models uncertainty using probability theory and Bayesian frameworks.
- Includes graphical models, probabilistic inference, and decision making under uncertainty.
- Examples:
    - "Applying Bayesian networks for disease risk prediction from incomplete clinical data."
    - "Using probabilistic graphical models to infer social network influence patterns."

[label=label_4]
- Learns optimal behaviors through trial and error with environmental rewards.
- Formalized as Markov Decision Processes (MDPs), balancing exploration and exploitation.
- Examples:
    - "Training an agent to navigate a maze environment using Q-learning."
    - "Optimizing robotic grasping strategies via reinforcement learning."

[label=label_5]
- Extracts symbolic "if-then" rules from training data for classification and reasoning.
- Produces interpretable and compact decision logic.
- Examples:
    - "Learning decision rules for customer churn prediction."
    - "Extracting symbolic classification rules for fraud detection."

---

Respond strictly in JSON format:
{"action_type": "update", "predicted_label": "label_string"}

You MUST select the predicted_label exactly from this list:
["label_0", "label_1", "label_2", "label_3", "label_4", "label_5", "label_6"]

The predicted label should have occurred in memory, unless the memory is empty.
