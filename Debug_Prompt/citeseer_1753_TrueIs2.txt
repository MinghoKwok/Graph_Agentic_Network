You are a label prediction agent for scientific papers.

Each paper must be assigned one of the following labels:
- Label_0: Traditional IR systems, document summarization, statistical retrieval, ranking, evaluation metrics.
- Label_1: Hardware systems, CPU scheduling, low-level architecture, signal processing, FPGAs, circuit design.
- Label_2: Content-based indexing, information extraction from multimedia (e.g., text in video), neural methods for perceptual signals, structured feature extraction.
- Label_3: Natural language summarization, document-level discourse models, linguistic feature selection, syntactic/semantic scoring.
- Label_4: Keyphrase extraction, topic modeling, knowledge-based methods.
- Label_5: Mobile agents, distributed software systems, remote computation.

Your goal is to classify a new paper based on its abstract and a memory of examples from other labeled papers. Please think step by step:

---

### ðŸ“„ Text to classify:
"Creating and Evaluating Multi-Document Sentence Extract Summaries  
This paper discusses passage extraction approaches to multi-document summarization that use available information about the document set as a whole and the relationships between the documents to build on single document summarization methodology. Multi-document summarization differs from single in that the issues of compression, speed, redundancy and passage selection are critical in the formation of useful summaries, as well as the user's goals in creating the summary. Our approach addresses these issues by using domain-independent techniques based mainly on fast, statistical processing, a metric for reducing redundancy and maximizing diversity in the selected passages, and a modular framework to allow easy parameterization for different genres, corpora characteristics and user requirements. We examined how humans create multi-document summaries as well as the characteristics of such summaries and use these summaries to evaluate the performance of various multi-document summarization algorithms."

---

### ðŸ§  Memory items:
1. **[Label_2]** "Automatic Text Detection and Tracking in Digital Video" â€“ Using neural networks and SSD tracking to extract text from video for indexing.
2. **[Label_2]** "Generating Extraction-Based Summaries from Hand-Written Summaries" â€“ Techniques for aligning sentence spans in news article summarization.
3. **[Label_0]** "Domain-Specific Informative and Indicative Summarization for IR" â€“ Structured summarization aligned with retrieval results.
4. **[Label_3]** "Selecting Text Spans for Document Summaries: Heuristics and Metrics" â€“ Ranking sentences for extractive summarization with linguistic features.
5. **[Label_3]** "Summarizing Text Documents: Sentence Selection and Evaluation Metrics" â€“ Evaluation of summary compression with linguistic/statistical features.
6. **[Label_0]** "Domain-Specific Keyphrase Extraction" â€“ Naive Bayes applied to document keyphrase extraction.
7. **[Label_1]** "Dynamic CPU Scheduling with Imprecise Knowledge of Computation-Time" â€“ Timing models and low-level OS scheduling.
8. **[Label_4]** "Keyphrase Extraction and Clustering for Document Metadata".

---

### ðŸ§© Instructions:

1. Analyze the abstract: determine if the paper is about **summarization**, **retrieval**, **indexing**, or **hardware**.
2. Identify which memory group it aligns with best.
3. Avoid over-relying on isolated keywords.
4. Output must be a JSON object with predicted label.

---

### ðŸ“¤ Output Format:
```json
{
  "action_type": "update",
  "predicted_label": "Label_X"
}
