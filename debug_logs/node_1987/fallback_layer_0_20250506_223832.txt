ðŸ“¤ [DEBUG] Fallback Prompt for Node 1987 | Layer 0 | 20250506_223832:
You are a label prediction agent.

You will be given a set of labeled memory items and a new node to classify.
Each example includes a few labeled texts as memory and a new text to classify.
Use the memory to predict the label for the current text.

## Example 1:
Memory:
1. [Label_2] "Hidden Markov models for sequence modeling and pattern discovery."
2. [Label_1] "Neural networks for text classification."
3. [Label_2] "Bayesian models for probabilistic inference."
Current Node Text:
"Markov models for speech sequence alignment."
Prediction: Label_2
Reasoning: The text discusses Markov models and speech alignment, which closely match Label_2 examples in memory.

## Example 2:
Memory:
1. [Label_2] "Hidden Markov models for biological sequence alignment."
2. [Label_6] "Improving ensemble model selection with probabilistic voting."
3. [Label_2] "Bayesian inference for protein sequence homology detection."
4. [Label_6] "Boosted decision trees for structured data classification."
5. [Label_3] "Non-reversible Markov chains for MCMC sampling."
Current Node Text:
"Homology detection in genetic sequences using Bayesian Markov modeling."
Prediction: Label_2
Reasoning: Although both Label_2 and Label_6 are well represented in memory, the current node text focuses on homology detection and Bayesian modeling, which strongly aligns with Label_2 examples related to biological sequences and probabilistic inference, rather than ensemble or structured classifiers.

## Your Turn:
Memory:
1. [Label_0] "Improving Minority Class Prediction Using Case-Specific Feature Weights Abstract: This paper addresses the problem of handling skewed class distributi..."
2. [Label_0] "Oblivious Decision Trees and Abstract Cases Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant featu..."
3. [Label_6] "Efficient Algorithms for Identifying Relevant Features Abstract: This paper describes efficient methods for exact and approximate implementation of th..."
4. [Label_0] "EXPLORING A FRAMEWORK FOR INSTANCE BASED LEARNING AND NAIVE BAYESIAN CLASSIFIERS Abstract: The relative performance of different methods for classifie..."
5. [Label_6] "On learning hierarchical classifications Abstract: Many significant real-world classification tasks involve a large number of categories which are arr..."

Text to classify:
"Improving Minority Class Prediction Using Case-Specific Feature Weights
Abstract: This paper addresses the problem of handling skewed class distributions within the case-based learning (CBL) framework. We first present as a baseline an information-gain-weighted CBL algorithm and apply it to three data sets from natural language processing (NLP) with skewed class distributions. Although overall performance of the baseline CBL algorithm is good, we show that the algorithm exhibits poor performance on minority class instances. We then present two CBL algorithms designed to improve the performance of minority class predictions. Each variation creates test-case-specific feature weights by first observing the path taken by the test case in a decision tree created for the learning task, and then using path-specific information gain values to create an appropriate weight vector for use during case retrieval. When applied to the NLP data sets, the algorithms are shown to significantly increase the accuracy of minority class predictions while maintaining or improving overall classification accuracy."

Respond strictly in JSON:
{"action_type": "update", "predicted_label": "Label_X"}
Allowed labels: ["Label_0", "Label_1", "Label_2", "Label_3", "Label_4", "Label_5", "Label_6"]

================================================================================