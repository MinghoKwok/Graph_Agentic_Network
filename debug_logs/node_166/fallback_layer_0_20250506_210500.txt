ðŸ“¤ [DEBUG] Fallback Prompt for Node 166 | Layer 0 | 20250506_210500:
You are a label prediction agent.

You will be given a set of labeled memory items and a new node to classify.
Each example includes a few labeled texts as memory and a new text to classify.
Use the memory to predict the label for the current text.

## Example 1:
Memory:
1. [Label_2] "Hidden Markov models for sequence modeling and pattern discovery."
2. [Label_1] "Neural networks for text classification."
3. [Label_2] "Bayesian models for probabilistic inference."
Current Node Text:
"Markov models for speech sequence alignment."
Prediction: Label_2
Reasoning: The text discusses Markov models and speech alignment, which closely match Label_2 examples in memory.

## Example 2:
Memory:
1. [Label_2] "Hidden Markov models for biological sequence alignment."
2. [Label_6] "Improving ensemble model selection with probabilistic voting."
3. [Label_2] "Bayesian inference for protein sequence homology detection."
4. [Label_6] "Boosted decision trees for structured data classification."
5. [Label_3] "Non-reversible Markov chains for MCMC sampling."
Current Node Text:
"Homology detection in genetic sequences using Bayesian Markov modeling."
Prediction: Label_2
Reasoning: Although both Label_2 and Label_6 are well represented in memory, the current node text focuses on homology detection and Bayesian modeling, which strongly aligns with Label_2 examples related to biological sequences and probabilistic inference, rather than ensemble or structured classifiers.

## Your Turn:
Memory:
1. [Label_0] "Formalising the knowledge content of case memory systems Abstract: Discussions of case-based reasoning often reflect an implicit assumption that a cas..."
2. [Label_0] "A Comparative Utility Analysis of Case-Based Reasoning and Control-Rule Learning Systems Abstract: The utility problem in learning systems occurs when..."
3. [Label_5] "The Difficulties of Learning Logic Programs with Cut Abstract: As real logic programmers normally use cut (!), an effective learning procedure for log..."
4. [Label_5] "on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples Abstract: This paper presents a method for learning..."
5. [Label_0] "LINNEO A Classification Methodology for Ill-structured Domains Abstract: In this work we present a classification methodology (LINNEO + ) to discover ..."

Text to classify:
"Rules and Precedents as Complementary Warrants Complementarity of Rules and Precedents for Classification In a
Abstract: This paper describes a model of the complementarity of rules and precedents in the classification task. Under this model, precedents assist rule-based reasoning by operationalizing abstract rule antecedents. Conversely, rules assist case-based reasoning through case elaboration, the process of inferring case facts in order to increase the similarity between cases, and term reformulation, the process of replacing a term whose precedents only weakly match a case with terms whose precedents strongly match the case. Fully exploiting this complementarity requires a control strategy characterized by impartiality, the absence of arbitrary ordering restrictions on the use of rules and precedents. An impartial control strategy was implemented in GREBE in the domain of Texas worker's compensation law. In a preliminary evaluation, GREBE's performance was found to be as good or slightly better than the performance of law students on the same task. A case is classified as belonging to a particular category by relating its description to the criteria for category membership. The justifications, or warrants [Toulmin, 1958], that can relate a case to a category, can vary widely in the generality of their antecedents. For example, consider warrants for classifying a case into the legal category "negligence." A rule, such as "An action is negligent if the actor fails to use reasonable care and the failure is the proximate cause of an injury," has very general antecedent terms (e.g., "breach of reasonable care"). Conversely, a precedent, such as "Dr. Jones was negligent because he failed to count sponges during surgery and as a result left a sponge in Smith," has very specific antecedent terms (e.g., "failure to count sponges"). Both types of warrants have been used by classification systems to relate cases to categories. Classification systems have used precedents to help match the antecedents of rules with cases. Completing this match is difficult when the terms in the antecedent are open-textured, i.e., when there is significant uncertainty whether they match specific facts [Gardner, 1984, McCarty and Sridharan, 1982]. This problem results from the "generality gap" separating abstract terms from specific facts [Porter et al., 1990]. Precedents of an open-textured term, i.e., past cases to which the term applied, can be used to bridge this gap. Unlike rule antecedents, the antecedents of precedents are at the same level of generality as cases, so no generality gap exists between precedents and new cases. Precedents therefore reduce the problem of matching specific case facts with open-textured terms to the problem of matching two sets of specific facts. For example, an injured employee's entitlement to worker's compensation depends on whether he was injured during an activity "in furtherance of employment." Determining whether any particular case should be classified as a compensable injury therefore requires matching the specific facts of the case (e.g., John was injured in an automobile accident while driving to his office) to the open-textured term "activity in furtherance of employment." The gap in generality between the case description and the abstract term makes this match problematical. However, completing this match may be much easier if there are precedents of the term "activity in furtherance of employment" (e.g., Mary's injury was not compensable because it occurred while she was driving to work, which is not an activity in furtherance of employment; Bill's injury was compensable because it occurred while he was driving to a house to deliver a pizza, an activity in furtherance of employment). In this case, John's driving to his office closely matches Mary's driving to work, so"

Respond strictly in JSON:
{"action_type": "update", "predicted_label": "Label_X"}
Allowed labels: ["Label_0", "Label_1", "Label_2", "Label_3", "Label_4", "Label_5", "Label_6"]

================================================================================