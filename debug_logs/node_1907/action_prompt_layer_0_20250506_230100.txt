
ðŸ“¤ [DEBUG] Action Prompt for Node 1907 | Layer 0 | 20250506_230100:

    You are Node 1907 in a scientific citation network. Your task is to classify yourself into the correct research category based on your text and connections.
    
    ## Few-shot Examples of Label Prediction:

    Example 1:
    Memory:
    1. [Neural_Networks] "A novel deep learning approach for image classification..."
    2. [Reinforcement_Learning] "Q-learning based algorithm for game playing..."
    3. [Neural_Networks] "Convolutional neural networks for computer vision tasks..."

    Current Node Text:
    "Deep learning models for visual recognition tasks..."

    Prediction: Neural_Networks
    Reasoning: The current text focuses on deep learning and visual recognition, which closely matches the Neural_Networks examples in memory.

    Example 2:
    Memory:
    1. [Probabilistic_Methods] "Bayesian networks for uncertainty modeling..."
    2. [Neural_Networks] "Recurrent neural networks for sequence prediction..."
    3. [Probabilistic_Methods] "Markov models for time series analysis..."

    Current Node Text:
    "Hidden Markov models for speech recognition..."

    Prediction: Probabilistic_Methods
    Reasoning: The text discusses Markov models, which is a probabilistic method, matching the Probabilistic_Methods examples in memory.

    Example 3:
    Memory:
    1. [Neural_Networks] "Deep learning architectures for natural language processing..."
    2. [Theory] "Theoretical analysis of algorithm complexity..."
    3. [Neural_Networks] "Transformer models for sequence modeling..."

    Current Node Text:
    "Attention mechanisms in deep learning models for text understanding..."

    Prediction: Neural_Networks
    Reasoning: Although the text mentions theoretical concepts like attention mechanisms, the focus is on deep learning models and their application to text understanding, which closely matches the Neural_Networks examples in memory.
    
    ## Your State:
    - Node ID: 1907
    - Layer: 0
    - Your Text:
    "Toward Rational Planning and Replanning Rational Reason Maintenance, Reasoning Economies, and Qualitative Preferences formal notions
Abstract: Efficiency dictates that plans for large-scale distributed activities be revised incrementally, with parts of plans being revised only if the expected utility of identifying and revising the subplans improves on the expected utility of using the original plan. The problems of identifying and reconsidering the subplans affected by changed circumstances or goals are closely related to the problems of revising beliefs as new or changed information is gained. But traditional techniques of reason maintenance|the standard method for belief revision|choose revisions arbitrarily and enforce global notions of consistency and groundedness which may mean reconsidering all beliefs or plan elements at each step. To address these problems, we developed (1) revision methods aimed at revising only those beliefs and plans worth revising, and tolerating incoherence and ungroundedness when these are judged less detrimental than a costly revision effort, (2) an artificial market economy in planning and revision tasks for arriving at overall judgments of worth, and (3) a representation for qualitative preferences that permits capture of common forms of dominance information. We view the activities of intelligent agents as stemming from interleaved or simultaneous planning, replanning, execution, and observation subactivities. In this model of the plan construction process, the agents continually evaluate and revise their plans in light of what happens in the world. Planning is necessary for the organization of large-scale activities because decisions about actions to be taken in the future have direct impact on what should be done in the shorter term. But even if well-constructed, the value of a plan decays as changing circumstances, resources, information, or objectives render the original course of action inappropriate. When changes occur before or during execution of the plan, it may be necessary to construct a new plan by starting from scratch or by revising a previous plan. only the portions of the plan actually affected by the changes. Given the information accrued during plan execution, which remaining parts of the original plan should be salvaged and in what ways should other parts be changed? Incremental replanning first involves localizing the potential changes or conflicts by identifying the subset of the extant beliefs and plans in which they occur. It then involves choosing which of the identified beliefs and plans to keep and which to change. For greatest efficiency, the choices of what portion of the plan to revise and how to revise it should be based on coherent expectations about and preferences among the consequences of different alternatives so as to be rational in the sense of decision theory (Savage 1972). Our work toward mechanizing rational planning and replanning has focussed on four main issues: This paper focusses on the latter three issues; for our approach to the first, see (Doyle 1988; 1992). Replanning in an incremental and local manner requires that the planning procedures routinely identify the assumptions made during planning and connect plan elements with these assumptions, so that replan-ning may seek to change only those portions of a plan dependent upon assumptions brought into question by new information. Consequently, the problem of revising plans to account for changed conditions has much"
    - Neighbors: [1800, 1995, 2301]
    - Available labeled neighbors to retrieve from: None
    - Neighbors with predicted labels: None
    
    You are an autonomous agent with planning capabilities. You may perform multiple actions in sequence to achieve better results.

    ## Decide Your Next Action(s)
    Important: You are allowed and encouraged to return MULTIPLE actions in sequence. You MUST respond with a JSON array even if there's only one action. 
    Example of a valid response:
    ```json
    [
      {"action_type": "update", "predicted_label": "Neural_Networks"},
      {"action_type": "broadcast"}
    ]
    ```
    ```json
    [
      {"action_type": "retrieve", "target_nodes": [1, 2, 3], "info_type": "text"},
      {"action_type": "rag_query", "query": "machine learning", "top_k": 10}
    ]
    ```
    Invalid response:
    ```json
    {"action_type": "update", "predicted_label": "Neural_Networks"}
    ```

    ### Available Actions:

    1. "retrieve": get information from other nodes
    - Format: {"action_type": "retrieve", "target_nodes": [IDs], "info_type": "text"}

    2. "broadcast": send a message to neighbors if and *only* if you already have a label or predicted label
    - Format: {"action_type": "broadcast", "target_nodes": [IDs], "message": "some message"}
    - Use this *only* when you already have a label orpredicted label to share it with neighbors. 
    - You MUST NOT use "broadcast" unless you already have a label orpredicted label (i.e., after an "update" action).
    - So "update" action always works before "broadcast" in the same layer.

    
        3. "update": decide your label *only* when the memory has enough information(labeled nodes, with text and label)
        - Format: {"action_type": "update", "predicted_label": choose one of allowed labels: ["Label_0", "Label_1", "Label_2", "Label_3", "Label_4", "Label_5", "Label_6"]}
        - You MUST choose one of the allowed label strings exactly as listed.
        - You MUST base your decision only on the definitions of the labels and the memory nodes with known labels.
        - You should ALWAYS follow this action with a "broadcast" to share your label with neighbors.

    4. "rag_query": search globally for similar labeled nodes, can make up "retrieve" action
    - Format: {"action_type": "rag_query", "query": [Your node ID, e.g. 13/57], "top_k": number of nodes to retrieve}
    - Use this when you don't have enough informative neighbors or memory, and need global examples.
    - You must use your own node ID as the query.

    5. "no_op": take no action
    - Format: {"action_type": "no_op"}

    

    ## Planning Your Steps
    1. If you have a predicted label, you can choose to broadcast it or continue to retrieve nodes with labels.
    2. If you don't have a predicted label, think like a planner: first gather evidence (retrieve, rag_query), then make a decision (update), and finally help others (broadcast).
    Think about the following:
    - If you cannot predict your label yet, need more context to predict your label â†’ `retrieve`, `rag_query`
    - Are you confident to predict your label? â†’ `update`
    - Have you shared your label or predicted label with neighbors? â†’ `broadcast`
    - Only broadcast if you have a predicted label or training label, AND your memory is not empty. If not, choose "retrieve" or "rag_query" first.
    - If any neighbors already have predicted labels, it is recommended to retrieve from them first.
    
================================================================================