
ðŸ“¤ [DEBUG] Action Prompt for Node 1339 | Layer 0 | 20250506_223050:

    You are Node 1339 in a scientific citation network. Your task is to classify yourself into the correct research category based on your text and connections.
    
    ## Few-shot Examples of Label Prediction:

    Example 1:
    Memory:
    1. [Neural_Networks] "A novel deep learning approach for image classification..."
    2. [Reinforcement_Learning] "Q-learning based algorithm for game playing..."
    3. [Neural_Networks] "Convolutional neural networks for computer vision tasks..."

    Current Node Text:
    "Deep learning models for visual recognition tasks..."

    Prediction: Neural_Networks
    Reasoning: The current text focuses on deep learning and visual recognition, which closely matches the Neural_Networks examples in memory.

    Example 2:
    Memory:
    1. [Probabilistic_Methods] "Bayesian networks for uncertainty modeling..."
    2. [Neural_Networks] "Recurrent neural networks for sequence prediction..."
    3. [Probabilistic_Methods] "Markov models for time series analysis..."

    Current Node Text:
    "Hidden Markov models for speech recognition..."

    Prediction: Probabilistic_Methods
    Reasoning: The text discusses Markov models, which is a probabilistic method, matching the Probabilistic_Methods examples in memory.

    Example 3:
    Memory:
    1. [Neural_Networks] "Deep learning architectures for natural language processing..."
    2. [Theory] "Theoretical analysis of algorithm complexity..."
    3. [Neural_Networks] "Transformer models for sequence modeling..."

    Current Node Text:
    "Attention mechanisms in deep learning models for text understanding..."

    Prediction: Neural_Networks
    Reasoning: Although the text mentions theoretical concepts like attention mechanisms, the focus is on deep learning models and their application to text understanding, which closely matches the Neural_Networks examples in memory.
    
    ## Your State:
    - Node ID: 1339
    - Layer: 0
    - Your Text:
    "An Analysis of Bayesian Classifiers (1988), involves the formulation of average-case models for specific algorithms
Abstract: In this paper we present an average-case analysis of the Bayesian classifier, a simple induction algorithm that fares remarkably well on many learning tasks. Our analysis assumes a monotone conjunctive target concept, and independent, noise-free Boolean attributes. We calculate the probability that the algorithm will induce an arbitrary pair of concept descriptions and then use this to compute the probability of correct classification over the instance space. The analysis takes into account the number of training instances, the number of attributes, the distribution of these attributes, and the level of class noise. We also explore the behavioral implications of the analysis by presenting predicted learning curves for artificial domains, and give experimental results on these domains as a check on our reasoning. One goal of research in machine learning is to discover principles that relate algorithms and domain characteristics to behavior. To this end, many researchers have carried out systematic experimentation with natural and artificial domains in search of empirical regularities (e.g., Kibler & Langley, 1988). Others have focused on theoretical analyses, often within the paradigm of probably approximately correct learning (e.g., Haus-sler, 1990). However, most experimental studies are based only on informal analyses of the learning task, whereas most formal analyses address the worst case, and thus bear little relation to empirical results. ber of attributes, and the class and attribute frequencies, they obtain predictions about the behavior of induction algorithms and used experiments to check their analyses. 1 However, their research does not focus on algorithms typically used by the experimental and practical sides of machine learning, and it is important that average-case analyses be extended to such methods. Recently, there has been growing interest in probabilistic approaches to inductive learning. For example, Fisher (1987) has described Cobweb, an incremental algorithm for conceptual clustering that draws heavily on Bayesian ideas, and the literature reports a number of systems that build on this work (e.g., Allen & Lang-ley, 1990; Iba & Gennari, 1991; Thompson & Langley, 1991). Cheeseman et al. (1988) have outlined Auto-Class, a nonincremental system that uses Bayesian methods to cluster instances into groups, and other researchers have focused on the induction of Bayesian inference networks (e.g., Cooper & Kerskovits, 1991). These recent Bayesian learning algorithms are complex and not easily amenable to analysis, but they share a common ancestor that is simpler and more tractable. This supervised algorithm, which we refer to simply as a Bayesian classifier, comes originally from work in pattern recognition (Duda & Hart, 1973). The method stores a probabilistic summary for each class; this summary contains the conditional probability of each attribute value given the class, as well as the probability (or base rate) of the class. This data structure approximates the representational power of a perceptron; it describes a single decision boundary through the instance space. When the algorithm encounters a new instance, it updates the probabilities stored with the specified class. Neither the order of training instances nor the occurrence of classification errors have any effect on this process. When given a test instance, the classifier uses an evaluation function (which we describe in detail later) to rank the alter"
    - Neighbors: [434, 1111, 1335, 1570, 1678, 2443, 2677]
    - Available labeled neighbors to retrieve from: None
    - Neighbors with predicted labels: None
    
    You are an autonomous agent with planning capabilities. You may perform multiple actions in sequence to achieve better results.

    ## Decide Your Next Action(s)
    Important: You are allowed and encouraged to return MULTIPLE actions in sequence. You MUST respond with a JSON array even if there's only one action. 
    Example of a valid response:
    ```json
    [
      {"action_type": "update", "predicted_label": "Neural_Networks"},
      {"action_type": "broadcast"}
    ]
    ```
    ```json
    [
      {"action_type": "retrieve", "target_nodes": [1, 2, 3], "info_type": "text"},
      {"action_type": "rag_query", "query": "machine learning", "top_k": 10}
    ]
    ```
    Invalid response:
    ```json
    {"action_type": "update", "predicted_label": "Neural_Networks"}
    ```

    ### Available Actions:

    1. "retrieve": get information from other nodes
    - Format: {"action_type": "retrieve", "target_nodes": [IDs], "info_type": "text"}

    2. "broadcast": send a message to neighbors if and *only* if you already have a label or predicted label
    - Format: {"action_type": "broadcast", "target_nodes": [IDs], "message": "some message"}
    - Use this *only* when you already have a label orpredicted label to share it with neighbors. 
    - You MUST NOT use "broadcast" unless you already have a label orpredicted label (i.e., after an "update" action).
    - So "update" action always works before "broadcast" in the same layer.

    
        3. "update": decide your label *only* when the memory has enough information(labeled nodes, with text and label)
        - Format: {"action_type": "update", "predicted_label": choose one of allowed labels: ["Label_0", "Label_1", "Label_2", "Label_3", "Label_4", "Label_5", "Label_6"]}
        - You MUST choose one of the allowed label strings exactly as listed.
        - You MUST base your decision only on the definitions of the labels and the memory nodes with known labels.
        - You should ALWAYS follow this action with a "broadcast" to share your label with neighbors.

    4. "rag_query": search globally for similar labeled nodes, can make up "retrieve" action
    - Format: {"action_type": "rag_query", "query": [Your node ID, e.g. 13/57], "top_k": number of nodes to retrieve}
    - Use this when you don't have enough informative neighbors or memory, and need global examples.
    - You must use your own node ID as the query.

    5. "no_op": take no action
    - Format: {"action_type": "no_op"}

    

    ## Planning Your Steps
    1. If you have a predicted label, you can choose to broadcast it or continue to retrieve nodes with labels.
    2. If you don't have a predicted label, think like a planner: first gather evidence (retrieve, rag_query), then make a decision (update), and finally help others (broadcast).
    Think about the following:
    - If you cannot predict your label yet, need more context to predict your label â†’ `retrieve`, `rag_query`
    - Are you confident to predict your label? â†’ `update`
    - Have you shared your label or predicted label with neighbors? â†’ `broadcast`
    - Only broadcast if you have a predicted label or training label, AND your memory is not empty. If not, choose "retrieve" or "rag_query" first.
    - If any neighbors already have predicted labels, it is recommended to retrieve from them first.
    
================================================================================