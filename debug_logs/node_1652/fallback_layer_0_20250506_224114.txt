ðŸ“¤ [DEBUG] Fallback Prompt for Node 1652 | Layer 0 | 20250506_224114:
You are a label prediction agent.

You will be given a set of labeled memory items and a new node to classify.
Each example includes a few labeled texts as memory and a new text to classify.
Use the memory to predict the label for the current text.

## Example 1:
Memory:
1. [Label_2] "Hidden Markov models for sequence modeling and pattern discovery."
2. [Label_1] "Neural networks for text classification."
3. [Label_2] "Bayesian models for probabilistic inference."
Current Node Text:
"Markov models for speech sequence alignment."
Prediction: Label_2
Reasoning: The text discusses Markov models and speech alignment, which closely match Label_2 examples in memory.

## Example 2:
Memory:
1. [Label_2] "Hidden Markov models for biological sequence alignment."
2. [Label_6] "Improving ensemble model selection with probabilistic voting."
3. [Label_2] "Bayesian inference for protein sequence homology detection."
4. [Label_6] "Boosted decision trees for structured data classification."
5. [Label_3] "Non-reversible Markov chains for MCMC sampling."
Current Node Text:
"Homology detection in genetic sequences using Bayesian Markov modeling."
Prediction: Label_2
Reasoning: Although both Label_2 and Label_6 are well represented in memory, the current node text focuses on homology detection and Bayesian modeling, which strongly aligns with Label_2 examples related to biological sequences and probabilistic inference, rather than ensemble or structured classifiers.

## Your Turn:
Memory Summary:
- Label_1: 3 examples
- Label_2: 5 examples
- Label_4: 2 examples

Memory:
1. [Label_2] "Modeling Cortical Plasticity Based on Adapting Lateral Interaction Abstract: A neural network model called LISSOM for the cooperative self-organizatio..."
2. [Label_2] "Separating hippocampal maps  Spatial Functions of the Hippocampal Formation and the Abstract: The place fields of hippocampal cells in old animals som..."
3. [Label_1] "An Artificial Life Model for Investigating the Evolution of Modularity Abstract: To investigate the issue of how modularity emerges in nature, we pres..."
4. [Label_1] "Growing neural networks Abstract: nan"
5. [Label_4] "Category: Control, Navigation and Planning. Key words: Reinforcement learning, Exploration, Hidden state. Prefer oral presentation. Abstract: This pap..."

Text to classify:
"A Theory of Visual Relative Motion Perception: Grouping, Binding, and Gestalt Organization
Abstract: The human visual system is more sensitive to the relative motion of objects than to their absolute motion. An understanding of motion perception requires an understanding of how neural circuits can group moving visual elements relative to one another, based upon hierarchical reference frames. We have modeled visual relative motion perception using a neural network architecture that groups visual elements according to Gestalt common-fate principles and exploits information about the behavior of each group to predict the behavior of individual elements. A simple competitive neural circuit binds visual elements together into a representation of a visual object. Information about the spiking pattern of neurons allows transfer of the bindings of an object representation from location to location in the neural circuit as the object moves. The model exhibits characteristics of human object grouping and solves some key neural circuit design problems in visual relative motion perception."

Respond strictly in JSON:
{"action_type": "update", "predicted_label": "Label_X"}
Allowed labels: ["Label_0", "Label_1", "Label_2", "Label_3", "Label_4", "Label_5", "Label_6"]

================================================================================