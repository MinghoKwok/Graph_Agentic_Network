ðŸ“¤ [DEBUG] Fallback Prompt for Node 555 | Layer 0 | 20250506_214922:
You are a label prediction agent.

You will be given a set of labeled memory items and a new node to classify.
Each example includes a few labeled texts as memory and a new text to classify.
Use the memory to predict the label for the current text.

Think step-by-step. Consider which label is best supported by both the semantic content of the node text and the examples in memory.
Do not rely on abstract or popular terms alone (like "system" or "accuracy") unless those match the label examples provided.

## Example 1:
Memory:
1. [Label_2] "Hidden Markov models for sequence modeling and pattern discovery."
2. [Label_1] "Neural networks for text classification."
3. [Label_2] "Bayesian models for probabilistic inference."
Current Node Text:
"Markov models for speech sequence alignment."
Prediction: Label_2
Reasoning: The text discusses Markov models and speech alignment, which closely match Label_2 examples in memory.

## Example 2:
Memory:
1. [Label_2] "Hidden Markov models for biological sequence alignment."
2. [Label_6] "Improving ensemble model selection with probabilistic voting."
3. [Label_2] "Bayesian inference for protein sequence homology detection."
4. [Label_6] "Boosted decision trees for structured data classification."
5. [Label_3] "Non-reversible Markov chains for MCMC sampling."
Current Node Text:
"Homology detection in genetic sequences using Bayesian Markov modeling."
Prediction: Label_2
Reasoning: Although both Label_2 and Label_6 are well represented in memory, the current node text focuses on homology detection and Bayesian modeling, which strongly aligns with Label_2 examples related to biological sequences and probabilistic inference, rather than ensemble or structured classifiers.

## Your Turn:
Memory Summary:
- Label_0: 2 examples
- Label_4: 5 examples
- Label_5: 1 examples
- Label_6: 3 examples

Memory:
1. [Label_4] "Scaling Reinforcement Learning Algorithms by Learning Variable Temporal Resolution Models Abstract: The close connection between reinforcement learnin..."
2. [Label_4] "Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems Abstract: Increasing attention has been paid to reinforcement learn..."
3. [Label_6] "Separating Formal Bounds from Practical Performance in Learning Systems Abstract: nan"
4. [Label_5] "Pac-Learning Recursive Logic Programs: Efficient Algorithms Abstract: We present algorithms that learn certain classes of function-free recursive logi..."
5. [Label_0] "Observation and Generalisation in a Simulated Robot World Abstract: This paper describes a program which observes the behaviour of actors in a simulat..."

Text to classify:
"Exactly Learning Automata with Small Cover Time
Abstract: We present algorithms for exactly learning unknown environments that can be described by deterministic finite automata. The learner performs a walk on the target automaton, where at each step it observes the output of the state it is at, and chooses a labeled edge to traverse to the next state. We assume that the learner has no means of a reset, and we also assume that the learner does not have access to a teacher that answers equivalence queries and gives the learner counterexamples to its hypotheses. We present two algorithms, one assumes that the outputs observed by the learner are always correct and the other assumes that the outputs might be erroneous. The running times of both algorithms are polynomial in the cover time of the underlying graph of the target automaton."

Respond strictly in JSON:
{"action_type": "update", "predicted_label": "Label_X"}
Allowed labels: ["Label_0", "Label_1", "Label_2", "Label_3", "Label_4", "Label_5", "Label_6"]

================================================================================