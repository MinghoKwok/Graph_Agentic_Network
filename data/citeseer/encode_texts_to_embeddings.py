# encode_texts_to_embeddings.py

from sentence_transformers import SentenceTransformer
import numpy as np
import json
from tqdm import tqdm

INPUT_PATH = "citeseer_text_graph_simplified.jsonl"
OUTPUT_PATH = "citeseer_text_embeddings.npy"
MODEL_NAME = "all-MiniLM-L6-v2"

def main():
    # åŠ è½½æ¨¡å‹
    model = SentenceTransformer(MODEL_NAME)
    print(f"âœ… Loaded sentence-transformer: {MODEL_NAME}")

    # åŠ è½½æ–‡æœ¬æ•°æ®
    records = []
    with open(INPUT_PATH, "r") as f:
        for line in f:
            record = json.loads(line)
            node_id = int(record["node_id"])  # ğŸ‘ˆ å¼ºåˆ¶è½¬æ¢ä¸º int
            records.append((node_id, record["text"]))

    node_ids = [nid for nid, _ in records]
    texts = [text for _, text in records]

    # æ‰¹é‡ç¼–ç 
    print(f"âš™ï¸ Encoding {len(texts)} texts...")
    embeddings = model.encode(
        texts,
        batch_size=32,
        show_progress_bar=True,
        normalize_embeddings=True  # ä¸º cosine æ£€ç´¢å‡†å¤‡
    )

    # å­˜ä¸º {node_id (int): embedding} dict
    result = {nid: emb for nid, emb in zip(node_ids, embeddings)}
    np.save(OUTPUT_PATH, result)
    print(f"âœ… Saved embeddings to {OUTPUT_PATH}")

if __name__ == "__main__":
    main()
