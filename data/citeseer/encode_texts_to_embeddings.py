from sentence_transformers import SentenceTransformer
import numpy as np
import json
from tqdm import tqdm

INPUT_PATH = "citeseer_text_graph_simplified.jsonl"
OUTPUT_PATH = "citeseer_text_embeddings_msmarco-MiniLM-L6-cos-v5.npy"  # ğŸ‘ˆ å»ºè®®ä¸åŒæ¨¡å‹ä¸åŒæ–‡ä»¶å
MODEL_NAME = "msmarco-MiniLM-L6-cos-v5"  # ğŸ‘ˆ å¯åˆ‡æ¢ä¸ºä½ è¦å°è¯•çš„æ¨¡å‹

# ğŸ” æ¨¡å‹é€‰æ‹©å»ºè®®ï¼š
# - "BAAI/bge-base-en-v1.5"       : ğŸ”¥æ¨èï¼é’ˆå¯¹ dense retrieval ä¼˜åŒ–ï¼Œè¯­ä¹‰è¡¨è¾¾å¼ºï¼Œé€‚åˆå­¦æœ¯ç±»æ–‡æœ¬
# - "intfloat/e5-base-v2"         : æ”¯æŒæŒ‡ä»¤å¼è¯­ä¹‰åµŒå…¥ï¼ˆInstruct Embeddingï¼‰ï¼Œæ•ˆæœä¹Ÿå¾ˆç¨³
# - "msmarco-MiniLM-L6-cos-v5"    : å¾®è°ƒäºæ£€ç´¢ä»»åŠ¡ï¼Œæ¯” all-MiniLM æ›´é€‚åˆå‘é‡æœç´¢
# - "all-MiniLM-L6-v2"            : åŸç‰ˆé€šç”¨æ¨¡å‹ï¼ˆå½“å‰ç”¨çš„ï¼‰ï¼Œé€Ÿåº¦å¿«ä½†æ£€ç´¢èƒ½åŠ›è¾ƒå¼±

def main():
    # åŠ è½½æ¨¡å‹
    model = SentenceTransformer(MODEL_NAME)
    print(f"âœ… Loaded embedding model: {MODEL_NAME}")

    # åŠ è½½æ–‡æœ¬æ•°æ®
    records = []
    with open(INPUT_PATH, "r") as f:
        for line in f:
            record = json.loads(line)
            node_id = int(record["node_id"])
            text = record["text"].strip()
            if not text:
                continue  # ğŸ‘ˆ è·³è¿‡ç©ºæ–‡æœ¬
            records.append((node_id, text))

    node_ids = [nid for nid, _ in records]
    texts = [text for _, text in records]

    print(f"âš™ï¸ Encoding {len(texts)} texts...")
    embeddings = model.encode(
        texts,
        batch_size=32,
        show_progress_bar=True,
        normalize_embeddings=True
    )

    result = {nid: emb for nid, emb in zip(node_ids, embeddings)}
    np.save(OUTPUT_PATH, result)
    print(f"âœ… Saved {len(result)} embeddings to {OUTPUT_PATH}")

if __name__ == "__main__":
    main()
