"""
Node agent implementation for the Graph Agentic Network
"""

import torch
from typing import Dict, List, Any, Optional, Tuple, Set, Union
from dataclasses import dataclass, field

from gan.actions import Action, RetrieveAction, RAGAction, BroadcastAction, UpdateAction, NoOpAction
from config import DEBUG_STEP_SUMMARY, DEBUG_MESSAGE_TRACE, NUM_LAYERS, DEBUG_FORCE_FALLBACK  # Âä†ÂÖ• NUM_LAYERS ‰ª•Âà§Êñ≠ÊòØÂê¶‰∏∫ÊúÄÂêé‰∏ÄÂ±Ç
from data.cora.label_vocab import label_vocab  # Ëá™ÂÆö‰πâÊ†áÁ≠æÊò†Â∞Ñ


@dataclass
class NodeState:
    """Represents the internal state of a node agent."""
    
    node_id: int
    text: str  # Âèñ‰ª£ features
    label: Optional[torch.Tensor] = None
    predicted_label: Optional[torch.Tensor] = None
    message_queue: List[Dict[str, Any]] = field(default_factory=list)
    memory: List[Dict[str, Any]] = field(default_factory=list)
    layer_count: int = 0
    
    def __post_init__(self):
        """Initialize hidden state if not provided."""
        pass

    def add_message(self, from_node: int, message: torch.Tensor, layer: int):
        self.message_queue.append({"from": from_node, "content": message, "layer": layer})

    def clear_messages(self):
        self.message_queue = []

    def increment_layer(self):
        self.layer_count += 1


class NodeAgent:
    """Represents an agent in the graph, corresponding to a node."""

    def __init__(self, state: NodeState, llm_interface: 'LLMInterface'):
        self.state = state
        self.llm = llm_interface
        self.retrieved_data = {}
        self.memory = {}

    def step(self, graph: 'AgenticGraph', layer: int):
        """Execute one step of the agent's decision-making process."""
        # ÂáÜÂ§á‰∏ä‰∏ãÊñá‰ø°ÊÅØ
        context = {
            "node_id": self.state.node_id,
            "text": self.state.text,
            "label": self.state.label.item() if self.state.label is not None else None,
            "layer": layer,
            "memory": self.state.memory,
            "neighbors": graph.get_neighbors(self.state.node_id),
            "total_neighbors": len(graph.get_neighbors(self.state.node_id))
        }
        
        # Ëé∑ÂèñÂä®‰ΩúÊèêÁ§∫
        action_prompt = self.llm._format_action_prompt(context, graph)
        
        try:
            # ÁîüÊàêÂìçÂ∫îÂπ∂Ëß£ÊûêÂä®‰Ωú
            response = self.llm.generate_response(action_prompt)
            action = self.llm.parse_action(response)
            
            # Â¶ÇÊûúËß£ÊûêÂ§±Ë¥•Ôºå‰ΩøÁî®Â§áÁî®ÂÜ≥Á≠ñ
            if action is None:
                print(f"‚ö†Ô∏è Failed to parse action from response: {response}")
                fallback_prompt = f"""Based on the following context, choose the most appropriate action:
Context: {context}
Available actions: retrieve, broadcast, update, rag_query
Choose one action and provide parameters."""
                fallback_decision = self.llm.parse_action(self.llm.generate_response(fallback_prompt))
                if fallback_decision is None:
                    print("‚ö†Ô∏è Fallback decision also failed. Using default update action.")
                    action = UpdateAction()
                else:
                    action = fallback_decision
            
            # ÊâßË°åÂä®‰Ωú
            if isinstance(action, dict):
                action = self._create_action(action)
            if action:
                result = action.execute(self, graph)
            
            # Êõ¥Êñ∞ËÆ∞ÂøÜ
            self.state.memory.append({
                "layer": layer,
                "action": action.__class__.__name__,
                "result": result
            })
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error in agent step: {e}")
            # ‰ΩøÁî® fallback update Âä®‰ΩúÁªìÊûÑÔºåÁ°Æ‰øùÂê´ÊúâÂêàÊ≥ïÂèÇÊï∞
            fallback_prompt = self.llm._format_fallback_label_prompt(self.state.text, self.state.memory)
            print(f"\nüì¶ [Exception Fallback Prompt for Node {self.state.node_id}]:\n{fallback_prompt}")
            fallback_response = self.llm.generate_response(fallback_prompt)
            fallback_decision = self.llm.parse_action(fallback_response)
            print(f"üéØ [Exception Fallback Result]: {fallback_decision}")

            if isinstance(fallback_decision, dict) and fallback_decision.get("action_type") == "update":
                action = self._create_action(fallback_decision)
            else:
                action = NoOpAction()  # ÊúÄÂùèÊÉÖÂÜµ‰πü‰∏çË¶ÅÁõ¥Êé• new UpdateAction()

            if isinstance(action, dict):
                action = self._create_action(action)
            if action:
                result = action.execute(self, graph)

            self.state.memory.append({
                "layer": layer,
                "action": action.__class__.__name__,
                "result": result,
                "error": str(e)
            })


        # ‚úÖ ÊèíÂÖ•Âú® step() ÂáΩÊï∞ÊúÄÂºÄÂßãÔºåÊâìÂç∞ÊØè‰∏™ËäÇÁÇπÂΩìÂâçËÆ°ÂàíÁöÑÂÆåÊï¥ action ÂàóË°®
        print(f"\nüìã Multi-Action Plan | Node {self.state.node_id} | Layer {layer}")

        # ‚úÖ Áªü‰∏ÄÂåÖÊàê listÔºåÊó†ËÆ∫ÊòØ dict ËøòÊòØ Action ÂÆû‰æã
        if isinstance(action, dict):
            action_list = [action]
        elif isinstance(action, Action):
            action_list = [action]
        elif isinstance(action, list):
            action_list = action
        else:
            action_list = [NoOpAction()]  # fallback

        for idx, d in enumerate(action_list):
            print(f"  {idx+1}. {d}")


        # Ensure decisions is a list
        # Normalize the action output to a list to support multiple sequential actions per node step.
        # This enables LLMs to plan a sequence like: [retrieve ‚Üí update ‚Üí broadcast]

        for decision in action_list:
            action = self._create_action(decision)
            if action:
                action_type = decision.get("action_type") if isinstance(decision, dict) else action.__class__.__name__
                result = action.execute(self, graph)
                print(f"‚úÖ Executed {action_type} with result: {result}")
                self.state.memory.append({
                    "layer": layer,
                    "action": result.get("action", "unknown"),
                    "result": result,
                    "text": self.state.text,
                    "label": self.state.label.item() if self.state.label is not None else None
                })

        # === Fallback update logic: only trigger at the last layer ===
        # Trigger fallback update only if:
        # - in the last layer,
        # - no predicted label yet,
        # - no prior update action occurred,
        # - but memory contains labeled examples.
        if (layer == NUM_LAYERS - 1 and (DEBUG_FORCE_FALLBACK or (
            self.state.predicted_label is None and 
            not any(m.get("action") == "update" for m in self.state.memory) and 
            any(m.get("label") is not None for m in self.state.memory)))):

            # ÊûÑÈÄ† fallback prompt Âπ∂Êé®ÁêÜ
            fallback_prompt = self.llm._format_fallback_label_prompt(self.state.text, self.state.memory)
            print(f"\nüì¶ [Fallback Prompt for Node {self.state.node_id}]:\n{fallback_prompt}")
            fallback_response = self.llm.generate_response(fallback_prompt)
            fallback_decision = self.llm.parse_action(fallback_response)
            print(f"üéØ [Fallback Result]: {fallback_decision}")

            if isinstance(fallback_decision, dict) and fallback_decision.get("action_type") == "update":
                fallback_action = self._create_action(fallback_decision)
                if fallback_action:
                    fallback_result = fallback_action.execute(self, graph)
                    self.state.memory.append({
                        "layer": layer,
                        "action": "fallback_update",
                        "result": fallback_result,
                        "text": self.state.text,
                        "label": self.state.label.item() if self.state.label is not None else None
                    })
                    if DEBUG_STEP_SUMMARY:
                        print(f"\nüîÑ Fallback Update | Node {self.state.node_id}")
                        print(f"  ‚îú‚îÄ üéØ New Label: {self.state.predicted_label}")
                        print(f"  ‚îî‚îÄ üìù Based on {len([m for m in self.state.memory if m.get('label') is not None])} labeled examples")
            else:
                print(f"‚ö†Ô∏è Fallback decision did not yield a valid update action. Skipping fallback update.")

        if (DEBUG_STEP_SUMMARY or DEBUG_MESSAGE_TRACE) and self.state.memory:
            last = self.state.memory[-1]
            action_type = last.get("action", "unknown")
            result = last.get("result", {})
            pred_label = self.state.predicted_label.item() if self.state.predicted_label is not None else None

            print(f"\nüß† Agent Step | Node {self.state.node_id} | Layer {layer}")
            print(f"  ‚îú‚îÄ üè∑Ô∏è  Action: {action_type}")
            print(f"  ‚îú‚îÄ üéØ Predicted Label: {pred_label}")
            print(f"  ‚îú‚îÄ üß† Memory size: {len(self.state.memory)}")
            print(f"  ‚îî‚îÄ üë• Total neighbors: {len(context.get('neighbors', []))}")

        if DEBUG_MESSAGE_TRACE and self.state.memory:
            print(f"\nüîç Message Trace | Node {self.state.node_id} | Layer {layer}")
            last = self.state.memory[-1]
            action_type = last.get("action", "unknown")
            result = last.get("result", {})
            # Show agent's most recent action result for debugging and traceability.
            # Useful for layer-wise inspection of node behavior.


            if action_type == "retrieve":
                targets = result.get("target_nodes", [])
                results = result.get("results", {})
                print(f"  üì• Retrieved from {len(targets)} target(s):")
                for tid in targets:
                    if tid in results:
                        preview_str = self._format_preview(results[tid])
                        print(f"    ‚Ü≥ Node {tid} ‚úÖ {preview_str}")
                    else:
                        print(f"    ‚Ü≥ Node {tid} ‚õî not found")
            elif action_type == "rag_query":
                print(f"  üîç RAG Query issued: {result.get('query')} (top-k: {len(result.get('results', []))})")
            elif action_type == "broadcast":
                targets = result.get("target_nodes", [])
                message = result.get("message", None)
                print(f"  üì§ Broadcasted to {len(targets)} node(s): {targets}")
                if message is not None:
                    preview = self._format_preview(message)
                    print(f"    ‚Ü≥ Message: {preview}")
            elif action_type == "update":
                updated = result.get("updated_fields", [])
                print(f"  üõ†Ô∏è  Updated fields: {updated}")
            else:
                print("  ‚ö†Ô∏è  No message or state updates in this step.")


    def receive_message(self, from_node: int, message: torch.Tensor) -> None:
        # ‚úÖ Âú® receive_message Êàñ receive_broadcast ‰∏≠‰πüÂä†ÂÖ•‰∏ÄË°åÁ°ÆËÆ§Êé•Êî∂
        print(f"üì® Node {self.state.node_id} received message from Node {from_node}")
        self.state.add_message(from_node, message, self.state.layer_count)

    def _prepare_context(self, graph: 'AgenticGraph') -> Dict[str, Any]:
        neighbors = [nid for nid in graph.get_neighbors(self.state.node_id) if nid != self.state.node_id]
        print(f"üîç Neighbors in prepare_context: {neighbors}")
        
        # ÊâæÂá∫Â∑≤ update ÁöÑÈÇªÂ±ÖÔºàÂç≥Êúâ predicted_label ÁöÑÈÇªÂ±ÖÔºâ
        updated_neighbors = [
            nid for nid in neighbors
            if graph.get_node(nid).state.predicted_label is not None
        ]
        print(f"üìä Updated neighbors (with predicted labels): {updated_neighbors}")
        
        messages = [{"from": msg["from"], "content_preview": msg["content"].mean().item(), "layer": msg["layer"]}
                    for msg in self.state.message_queue[-5:]]
        recent_memory = self.state.memory[-3:] if self.state.memory else []
        return {
            "node_id": self.state.node_id,
            "layer": self.state.layer_count,
            "text": self.state.text,
            "label": self.state.label.item() if self.state.label is not None else None,
            "predicted_label": self.state.predicted_label.item() if self.state.predicted_label is not None else None,
            "neighbors": neighbors,
            "total_neighbors": len(neighbors),
            "updated_neighbors": updated_neighbors,  # Ê∑ªÂä†Â∑≤Êõ¥Êñ∞ÈÇªÂ±ÖÂàóË°®
            "messages": messages,
            "total_messages": len(self.state.message_queue),
            "memory": recent_memory,
            "total_memory": len(self.state.memory),
            "retrieved_data": self.retrieved_data
        }

    def _create_action(self, decision: Dict[str, Any]) -> Optional[Action]:
        if isinstance(decision, dict):
            action_type = decision.get("action_type", "no_op")
        elif isinstance(decision, Action):
            return decision  # Â∑≤ÁªèÊòØÊûÑÈÄ†Â•ΩÁöÑ ActionÔºåÁõ¥Êé•ËøîÂõû
        else:
            print(f"‚ö†Ô∏è Unsupported decision type: {type(decision)}. Fallback to NoOp.")
            return NoOpAction()
        
        if action_type == "retrieve":
            target_nodes = decision.get("target_nodes", [])
            info_type = decision.get("info_type", "text")
            # Á°Æ‰øù info_type ÊòØÊîØÊåÅÁöÑÁ±ªÂûã
            if info_type not in ["text", "label", "both", "memory", "all"]:
                info_type = "text"  # ÈªòËÆ§‰ΩøÁî® "text"
            return RetrieveAction(target_nodes, info_type)
        
        elif action_type == "rag_query":
            query = decision.get("query", str(self.state.node_id))  # ÈªòËÆ§‰ΩøÁî®ËäÇÁÇπID‰Ωú‰∏∫Êü•ËØ¢
            top_k = decision.get("top_k", 5)  # ÈªòËÆ§Ëé∑Âèñ5‰∏™Áõ∏‰ººËäÇÁÇπ
            query = str(self.state.node_id)  # üëà Âº∫Âà∂‰ΩøÁî®ËäÇÁÇπËá™Ë∫´ÁöÑ ID ‰Ωú‰∏∫ query
            return RAGAction(query, top_k)

        elif action_type == "broadcast":
            target_nodes = decision.get("target_nodes", [])

            # ‚úÖ fallback message logic
            message_data = decision.get("message", None)

            if message_data is None:
                # fallback to predicted_label + text
                # If LLM does not provide a broadcast message, fallback to a default message combining predicted_label + text.
                # This ensures all broadcast actions remain valid and meaningful for downstream nodes.
                plabel = self.state.predicted_label.item() if self.state.predicted_label is not None else "unknown"
                text = self.state.text[:60] + "..." if len(self.state.text) > 60 else self.state.text
                fallback_message = f"[Label: {plabel}] {text}"
                print(f"‚ö†Ô∏è Broadcast message missing ‚Äî fallback to: {fallback_message}")
                message_data = fallback_message

            if isinstance(message_data, list) and all(isinstance(x, (int, float)) for x in message_data):
                message = torch.tensor(message_data, dtype=torch.float)
            elif isinstance(message_data, (int, float)):
                message = torch.tensor([message_data], dtype=torch.float)
            else:
                message = torch.tensor([len(str(message_data))], dtype=torch.float)

            return BroadcastAction(target_nodes, message)

        elif action_type == "update":
            updates = {}
            if "predicted_label" in decision:
                label_value = decision.get("predicted_label")
                
                # Direct integer label
                if isinstance(label_value, int) and 0 <= label_value < 7:
                    updates["predicted_label"] = torch.tensor(label_value)
                    print(f"‚úÖ Using direct integer label: {label_value}")
                
                # String label handling
                elif isinstance(label_value, str):
                    # Try parsing as integer first
                    try:
                        label_id = int(label_value)
                        if 0 <= label_id < 7:
                            updates["predicted_label"] = torch.tensor(label_id)
                            print(f"‚úÖ Parsed label string to integer: {label_value} -> {label_id}")
                    except ValueError:
                        # Try exact match with vocabulary
                        label_id = label_vocab.get(label_value, -1)
                        if label_id != -1:
                            updates["predicted_label"] = torch.tensor(label_id)
                            print(f"‚úÖ Mapped label string to ID: {label_value} -> {label_id}")
                        else:
                            # Try fuzzy matching
                            normalized = label_value.lower().strip()
                            if any(kw in normalized for kw in ["case", "based"]):
                                updates["predicted_label"] = torch.tensor(0)
                                print(f"‚úÖ Fuzzy match: {label_value} -> Case_Based (0)")
                            elif any(kw in normalized for kw in ["genetic", "algorithm", "evolution"]):
                                updates["predicted_label"] = torch.tensor(1)
                                print(f"‚úÖ Fuzzy match: {label_value} -> Genetic_Algorithms (1)")
                            elif any(kw in normalized for kw in ["neural", "network", "neuron"]):
                                updates["predicted_label"] = torch.tensor(2)
                                print(f"‚úÖ Fuzzy match: {label_value} -> Neural_Networks (2)")
                            elif any(kw in normalized for kw in ["probabilistic", "probability", "bayes"]):
                                updates["predicted_label"] = torch.tensor(3)
                                print(f"‚úÖ Fuzzy match: {label_value} -> Probabilistic_Methods (3)")
                            elif any(kw in normalized for kw in ["reinforcement", "reinforce"]):
                                updates["predicted_label"] = torch.tensor(4)
                                print(f"‚úÖ Fuzzy match: {label_value} -> Reinforcement_Learning (4)")
                            elif any(kw in normalized for kw in ["rule", "rule learning"]):
                                updates["predicted_label"] = torch.tensor(5)
                                print(f"‚úÖ Fuzzy match: {label_value} -> Rule_Learning (5)")
                            elif any(kw in normalized for kw in ["theory", "theoretical"]):
                                updates["predicted_label"] = torch.tensor(6)
                                print(f"‚úÖ Fuzzy match: {label_value} -> Theory (6)")
                            else:
                                print(f"‚ö†Ô∏è Failed to map label string: {label_value}")
            
            if updates:
                return UpdateAction(updates)
            else:
                print(f"‚ö†Ô∏è No valid predicted_label found in update decision: {decision}")

        return NoOpAction()

    def _format_preview(self, obj: Any, max_len: int = 60) -> str:
        """
        Format a preview string from any object for display.
        
        Args:
            obj: The object to preview
            max_len: Max number of characters
            
        Returns:
            Truncated string representation
        """
        try:
            if isinstance(obj, torch.Tensor):
                return str(obj.tolist()[:5]) + ("..." if obj.numel() > 5 else "")
            elif isinstance(obj, (list, tuple)):
                if all(isinstance(i, dict) for i in obj):
                    preview_list = [{k: v for k, v in item.items() if k in ("text", "predicted_label", "label")} for item in obj[:2]]
                    return str(preview_list) + ("..." if len(obj) > 2 else "")
                return str(obj[:5]) + ("..." if len(obj) > 5 else "")
            elif isinstance(obj, dict):
                keys = list(obj.keys())[:3]
                preview = {k: obj[k] for k in keys}
                return str(preview) + ("..." if len(obj) > 3 else "")
            elif isinstance(obj, (str, int, float, bool)):
                return str(obj)[:max_len] + ("..." if len(str(obj)) > max_len else "")
            elif obj is None:
                return "None"
            else:
                return str(type(obj))  # fallback: just print type name
        except Exception as e:
            return f"[Preview error: {e}]"
